{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc1f6db-4fb4-4b37-8e72-1096fcf60dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.vector_ar.vecm import VECM, coint_johansen, select_coint_rank, select_order\n",
    "# from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "# from statsmodels.tsa.vector_ar.vecm import coint_johansen, select_coint_rank\n",
    "from statsmodels.tsa.vector_ar import util\n",
    "from statsmodels.tools.validation import (\n",
    "    array_like,\n",
    "    bool_like,\n",
    "    int_like,\n",
    "    string_like,\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e3218f-59f7-48b5-ae7e-62e94d3285a3",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568b30e2-1fd0-45aa-be4b-d015fcf6b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lagged_inp(X,max_lag):\n",
    "    X = np.array(X)\n",
    "    lag_inputs = np.zeros((len(X) - max_lag, max_lag))\n",
    "    for i in range(max_lag):\n",
    "        lag_inputs[:, i] = X[max_lag - 1 - i: -1 - i]\n",
    "    return lag_inputs\n",
    "\n",
    "def fit_ols_model(X, Y, intercept = True):\n",
    "    if intercept:\n",
    "        X = sm.add_constant(X)  # Add a constant term to the exogenous variables\n",
    "    model = sm.OLS(Y,X)\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model\n",
    "\n",
    "class ARMAProcess:\n",
    "    def __init__(self, ar_params, ma_params):\n",
    "        self.ar_params = ar_params\n",
    "        self.ma_params = ma_params\n",
    "        \n",
    "    def generate_ARMA(self,n):\n",
    "        arma_process = ArmaProcess(self.ar_params, self.ma_params) ## polynomials to pass\n",
    "        return arma_process.generate_sample(n)\n",
    "    \n",
    "    def fit_model(self, data):\n",
    "        ar_model = sm.tsa.ARMA(data, order=(len(self.ar_params), len(self.ma_params)))\n",
    "        fitted_model = ar_model.fit()\n",
    "        return fitted_model\n",
    "        \n",
    "    def MC_sim_ARMA(self,MC_length,max_lag):\n",
    "        estim_models = []\n",
    "        IV_estims = []\n",
    "        relev_covar = []\n",
    "        for i in range(MC_length):\n",
    "            generated_samples = self.generate_ARMA(1000)\n",
    "            y = generated_samples \n",
    "            X = generate_lagged_inp(generated_samples,max_lag)\n",
    "            Z = generate_lagged_inp(X.reshape(-1,),1) ### Get x_(t-1) as the instrument variable because E(x_(t-1)*x_t) !=0 while its exogenous with erros\n",
    "            relev_covar.append(np.mean(X[1:]*Z))\n",
    "            OLS_fit = fit_ols_model(X,y[max_lag:],intercept = False)\n",
    "            IV_estim = np.linalg.inv(Z.T @ X[1:]) @ Z.T @ y[max_lag + 1:]\n",
    "            estim_models.append(OLS_fit)\n",
    "            IV_estims.append(IV_estim)\n",
    "        return estim_models, IV_estims, relev_covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c8389a-0a41-4c20-9fac-8be7f5a67602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E(Xz) = 6.511838017233015 across all simulations\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "ar_params = [0.8]  # AR parameter\n",
    "ma_params = [0.7]   # MA parameters\n",
    "ar = np.r_[1,-np.array(ar_params)]\n",
    "ma = np.r_[1,np.array(ma_params)]\n",
    "arma_process = ARMAProcess(ar, ma)\n",
    "OLS_sims_ARMA,IV_estims,relev_covar = arma_process.MC_sim_ARMA(1000,1)\n",
    "#residuals = OLS_sims_ARMA[100].resid\n",
    "coeffs = [sim_param.params[0] for sim_param in OLS_sims_ARMA]\n",
    "print(f\"E(Xz) = {np.mean(relev_covar)} across all simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73cebad9-f736-46e1-8863-6ae30f3650e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(coeffs).reshape(-1,), bins = 50, density = True)\n",
    "plt.title(f\"Estimated $\\phi$'s\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e4224a-a5e0-4c62-b3c8-36768c11b382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGzCAYAAACPa3XZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn/ElEQVR4nO3de3RU5b3/8c/kNhBI0MglCURARC6G4DogyK3AOSaISEXaqk1F8LLUCqeHxtbGsihDgZRCdeEN1hIt4KoptBasCgJRK6IpCghLFA4HSlBEAnJNJBIm5Pn9Mb8MHSYkk2T2k0zyfq01izXPPLP3d38z2fmwZ+8ZlzHGCAAAwJKoxi4AAAC0LIQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4ABrJ8uXL5XK5Lnt77733Ql5WYWGhPB6PTp8+Xe06Dh48GNbaG1JTOHg8Hrlcrno9t3///vrRj34UtlqqegwgdDGNXQDQ0i1btky9e/cOGu/bt2/IyygsLNTs2bM1ZcoUXXHFFf7xcePG6Z///KdSUlLCUWqdXK6mxnT27Fl9/vnnuvfeexu7FKBFI3wAjSw9PV0DBw50ZNkdOnRQhw4dHFl2JNq6dasuXLigm266qbFLAVo03nYBmrhvvvlGDz30kNLS0uR2u9WhQwcNGzZMb7/9tiTfWxC//OUvJUndu3cPeNumurddqt6y+PTTT/WjH/1I7dq1U1JSknJyclRRUaG9e/fqlltuUUJCgrp166YFCxYE1LN//37dd9996tmzp+Lj49W5c2eNHz9eu3btCljH5Wqqsm/fPmVnZ6tjx45yu93q06ePnn/++aDtX7t2rW644Qa53W51795df/jDH+rcwz/+8Y/KyMhQVlaWJCkzM1MTJkxQcXHxZZ8zbtw49ejRI2jcGKMbb7xRw4YNq/Z5tf28AHDkA2h0Fy5cUEVFRcCYy+VSdHS0JGnSpEn65JNPNG/ePF133XU6ffq0PvnkE504cUKS9OCDD+rkyZN69tlntXr1av9bLH379q3xXI8777xT99xzjx5++GEVFBRowYIF8nq9evvtt/Xoo4/qF7/4hfLz8/WrX/1K1157rSZOnChJ+vrrr3XVVVdp/vz56tChg06ePKkVK1Zo8ODB2rFjh3r16lVjTZK0e/duDR06VFdffbWefPJJJScna8OGDfrZz36m48ePa9asWZKkd955R7fffruGDBmilStX6sKFC1qwYIGOHj0acn8fe+wxLV68WDNnztTf//53lZSUaNq0aXrsscf04x//WP/4xz+qfd4NN9ygt956S99++63atm3rH3/55Ze1fft2ffzxx5KkKVOmaMqUKf7Ha/t5AZBkADSKZcuWGUnV3qKjo/3z2rZta6ZPn17jshYuXGgkmaKiomrX8e/js2bNMpLMk08+GTD3hhtuMJLM6tWr/WNer9d06NDBTJw48bLrrqioMOfPnzc9e/Y0P//5z2utyRhjxowZY7p06WLOnDkTMD5t2jTTqlUrc/LkSWOMMYMHDzapqanmu+++888pKSkxSUlJJpTd1+rVq40ks3LlSmOMMV26dDH333+/McaY+++/30gyR48eNcYYc+7cOdOpUydz+vRpY4wxq1atMpLMli1b/Mv79ttvTWpqqpkyZcpl1xnKzwto6XjbBWhkL7/8srZu3Rpw++ijj/yPDxo0SMuXL9fcuXO1ZcsWeb3esKz3tttuC7jfp08fuVwujR071j8WExOja6+9Vl988YV/rKKiQnl5eerbt6/i4uIUExOjuLg47du3T3v27Kl1vefOndM777yjO+64Q/Hx8aqoqPDfbr31Vp07d05btmzR2bNntXXrVk2cOFGtWrXyPz8hIUHjx48PaRufeeYZ3XDDDbrrrrt07NgxffXVV/7za6699lpJUmlpqSTJ7XaruLhY7dq1k+S7KkZSwNtJ8+fPV0lJifLy8i67Tqd+XkBzQvgAGlmfPn00cODAgNuAAQP8j69atUqTJ0/Wiy++qCFDhigpKUn33ntvjecrhCIpKSngflxcnOLj4wP+0FeNnzt3zn8/JydHM2fO1IQJE/TGG2/oo48+0tatW9W/f3999913ta73xIkTqqio0LPPPqvY2NiA26233ipJOn78uE6dOqXKykolJycHLaO6serW8/777/tD1rZt2yTJHz4OHz4st9utzp07S5KefvppPfjgg/7nV53TUhU+Dh06pCeffFK//vWva7x6yKmfF9CccM4H0MS1b99eixYt0qJFi/Tll1/q9ddfV25uro4dO6b169dbr+dPf/qT7r333qD//R8/fjykS2qvvPJKRUdHa9KkSZo6dWq1c7p3765WrVrJ5XJV+0c7lD/k+/fvV2VlpT9cbNu2TbGxscrIyJAxRm+++aZuu+02f9j69NNPlZGR4X9+VFSU0tPT/eHjV7/6lZKTk5WTk1PjepvazwtoiggfQAS5+uqrNW3aNL3zzjv68MMP/eNut1uSQjry0FAul8u/vipr167V4cOH/W9l1FRTfHy8Ro8erR07digjI0NxcXGXXdegQYO0evVqLVy40B8SSktL9cYbb9RaZ0JCgiSpqKhIki98pKeny+126/nnn9ehQ4e0YsUK//xPP/1U99xzT8Ay+vfvrzVr1mjLli1auXKl/vrXvwZte00u9/MCWjrCB9DIPvvss6CrXSSpR48eiouL0+jRo5Wdna3evXsrISFBW7du1fr16/1Xn0hSv379JPneOpg8ebJiY2PVq1cvR+q97bbbtHz5cvXu3VsZGRnavn27Fi5cqC5dugTMu1xNCQkJevrppzV8+HCNGDFCP/3pT9WtWzeVlpZq//79euONN/Tuu+9KkubMmaNbbrlFmZmZeuyxx3ThwgX9/ve/V5s2bXTy5Mka6+zTp4/69eunJUuWqE+fPtq6dav69eunmTNnav78+Zo3b55GjhwpSaqsrNTu3bsDjnxIvvCxdOlS3X///fre976nH/zgBzWu88yZMyH9vIAWr7HPeAVaqpqudpFkli5das6dO2ceeeQRk5GRYRITE03r1q1Nr169zKxZs8zZs2cDlvfEE0+Y1NRUExUVZSSZf/zjHzVe7fLNN98EPH/y5MmmTZs2QXWOHDnSXH/99f77p06dMg888IDp2LGjiY+PN8OHDzebN282I0eONCNHjqy1pipFRUXm/vvvN507dzaxsbGmQ4cOZujQoWbu3LkBy3j99ddNRkaGiYuLM1dffbWZP3++fxtqc+DAAZOZmWncbreRZOLi4syAAQPMX/7yl4B5e/fuNSkpKUHP37x5s5FkoqKizI4dO2pdX11+XkBL5jLGmMYIPQBgy2uvvaY77rhDu3btUnp6etDjr776ql588UXOyQAs4WoXAM3exx9/rLZt2172+3J27doV9JYLAOdw5ANAs/df//VfqqysvOynmQKwi/ABAACs4m0XAABgFeEDAABYRfgAAABWNbkPGausrNTXX3+thIQEuVyuxi4HAACEwBij0tJSpaamKiqq5mMbTS58fP3110pLS2vsMgAAQD0cOnQo6BOPL9XkwkfV9zEcOnRIiYmJQY97vV5t3LhRWVlZio2NtV1ek0EfLqIXPvTBhz740Acf+uBjow8lJSVKS0vz/x2vSZMLH1VvtSQmJl42fMTHxysxMbHFv5Dogw+98KEPPvTBhz740Acfm30I5ZQJTjgFAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVMY1dAABcqlvu2pDmHZw/LizLCmU5AMKHIx8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwqk7h43e/+51uvPFGJSQkqGPHjpowYYL27t0bMMcYI4/Ho9TUVLVu3VqjRo3S559/HtaiAQBA5Iqpy+RNmzZp6tSpuvHGG1VRUaEZM2YoKytLu3fvVps2bSRJCxYs0FNPPaXly5fruuuu09y5c5WZmam9e/cqISHBkY0A0DJ1y10bNOaONlowSEr3bFD5BVcjVAWgNnUKH+vXrw+4v2zZMnXs2FHbt2/X9773PRljtGjRIs2YMUMTJ06UJK1YsUKdOnVSfn6+Hn744fBVDgAAIlKdwselzpw5I0lKSkqSJBUVFam4uFhZWVn+OW63WyNHjlRhYWG14aO8vFzl5eX++yUlJZIkr9crr9cbNL9qrLrHWhL6cBG98GlOfXBHm/o/N8oE/BuK5tCzSzWn10ND0AcfG32oy7Jdxph6/ZYbY3T77bfr1KlT2rx5sySpsLBQw4YN0+HDh5Wamuqf+9BDD+mLL77Qhg0bgpbj8Xg0e/bsoPH8/HzFx8fXpzQAAGBZWVmZsrOzdebMGSUmJtY4t95HPqZNm6ZPP/1UH3zwQdBjLlfg+6zGmKCxKk888YRycnL890tKSpSWlqasrKxqi/d6vSooKFBmZqZiY2PrW37Eow8X0Quf5tSHdE/wf1RC5Y4ymjOwUjO3Ram8MrRzPj7zjKn3+pqq5vR6aAj64GOjD1XvXISiXuHjv//7v/X666/r/fffV5cuXfzjycnJkqTi4mKlpKT4x48dO6ZOnTpVuyy32y232x00HhsbW2ODanu8paAPF9ELn+bQh3CcKFpe6Qp5OZHer5o0h9dDONAHHyf7UJfl1ulSW2OMpk2bptWrV+vdd99V9+7dAx7v3r27kpOTVVBQ4B87f/68Nm3apKFDh9ZlVQAAoJmq05GPqVOnKj8/X3//+9+VkJCg4uJiSVK7du3UunVruVwuTZ8+XXl5eerZs6d69uypvLw8xcfHKzs725ENAAAAkaVO4WPJkiWSpFGjRgWML1u2TFOmTJEkPf744/ruu+/06KOP6tSpUxo8eLA2btzIZ3wAAABJdQwfoVwY43K55PF45PF46lsTAABoxvhuFwAAYBXhAwAAWNWgTzgFAFxU3XfNXOrg/HEWKgGaNo58AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrYhq7AACRoVvu2lrnHJw/zkIlACIdRz4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFVc7QIAFnHVEMCRDwAAYBnhAwAAWEX4AAAAVhE+AACAVYQPAABgFVe7AGjxuAIFsIsjHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKyKaewCALQs3XLXNnYJ9RKpdQNNEUc+AACAVXUOH++//77Gjx+v1NRUuVwuvfbaawGPT5kyRS6XK+B20003hateAAAQ4eocPs6ePav+/fvrueeeu+ycW265RUeOHPHf1q1b16AiAQBA81Hncz7Gjh2rsWPH1jjH7XYrOTm53kUBAIDmy5ETTt977z117NhRV1xxhUaOHKl58+apY8eO1c4tLy9XeXm5/35JSYkkyev1yuv1Bs2vGqvusZaEPlxEL3yc7oM72oRcQ0OX0xDuKBPwbyQKx8+Q3wsf+uBjow91WbbLGFPv31CXy6U1a9ZowoQJ/rFVq1apbdu26tq1q4qKijRz5kxVVFRo+/btcrvdQcvweDyaPXt20Hh+fr7i4+PrWxoAALCorKxM2dnZOnPmjBITE2ucG/bwcakjR46oa9euWrlypSZOnBj0eHVHPtLS0nT8+PFqi/d6vSooKFBmZqZiY2PrW3rEow8X0Qsfp/uQ7tlQ65zPPGPCspyGcEcZzRlYqZnbolRe6XJ0XU4JpY+14ffChz742OhDSUmJ2rdvH1L4cPxzPlJSUtS1a1ft27ev2sfdbne1R0RiY2NrbFBtj7cU9OEieuHjVB/KL9T+hzyU9YaynHAor3RZW1e4hfPnx++FD33wcbIPdVmu45/zceLECR06dEgpKSlOrwoAAESAOh/5+Pbbb7V//37//aKiIu3cuVNJSUlKSkqSx+PRD37wA6WkpOjgwYP69a9/rfbt2+uOO+4Ia+EAACAy1Tl8bNu2TaNHj/bfz8nJkSRNnjxZS5Ys0a5du/Tyyy/r9OnTSklJ0ejRo7Vq1SolJCSEr2oAABCx6hw+Ro0apZrOUd2wwdmTyQAAQGTju10AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWOf8IpgKavW+7axi4BQAvCkQ8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBVXuwDNHFeyAGhqOPIBAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAq/h4dQBoYkL5SPyD88dF3LqAKhz5AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXf7QI0UXznBoDmiiMfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqrnYBEDahXKEDu9I9G1R+wdXYZQABOPIBAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKziahcAiEC1XVnkjjZaMMhSMUAdceQDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgVZ3Dx/vvv6/x48crNTVVLpdLr732WsDjxhh5PB6lpqaqdevWGjVqlD7//PNw1QsAACJcncPH2bNn1b9/fz333HPVPr5gwQI99dRTeu6557R161YlJycrMzNTpaWlDS4WAABEvpi6PmHs2LEaO3ZstY8ZY7Ro0SLNmDFDEydOlCStWLFCnTp1Un5+vh5++OGGVQsAACJencNHTYqKilRcXKysrCz/mNvt1siRI1VYWFht+CgvL1d5ebn/fklJiSTJ6/XK6/UGza8aq+6xloQ+XNRce+GONrXO+fdtvlwfQllOc+KOMgH/tlTh7EMk/2411/1DXdnoQ12W7TLG1PuV6XK5tGbNGk2YMEGSVFhYqGHDhunw4cNKTU31z3vooYf0xRdfaMOGDUHL8Hg8mj17dtB4fn6+4uPj61saAACwqKysTNnZ2Tpz5owSExNrnBvWIx9VXC5XwH1jTNBYlSeeeEI5OTn++yUlJUpLS1NWVla1xXu9XhUUFCgzM1OxsbHhLTyC0IeLmmsv0j3BYb0m7iijOQMrNXNblMorq/99awnog084+/CZZ0yYqrKvue4f6spGH6reuQhFWMNHcnKyJKm4uFgpKSn+8WPHjqlTp07VPsftdsvtdgeNx8bG1tig2h5vKejDRc2tF+UX6vcHo7zSVe/nNif0wSccfWgOv1fNbf9QX072oS7LDevnfHTv3l3JyckqKCjwj50/f16bNm3S0KFDw7kqAAAQoep85OPbb7/V/v37/feLioq0c+dOJSUl6eqrr9b06dOVl5ennj17qmfPnsrLy1N8fLyys7PDWjgAAIhMdQ4f27Zt0+jRo/33q87XmDx5spYvX67HH39c3333nR599FGdOnVKgwcP1saNG5WQkBC+qgEAQMSqc/gYNWqUarpAxuVyyePxyOPxNKQuAADQTDlytQvQknXLXdvYJQBAk8YXywEAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALAqprELAABEvm65a2udc3D+OAuVIBJw5AMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVfLcLUAehfH8F0Nzwuke4ceQDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFjF1S7A/8cZ/QBgB0c+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYFfbw4fF45HK5Am7JycnhXg0AAIhQMU4s9Prrr9fbb7/tvx8dHe3EagAAQARyJHzExMRwtAMAAFTLkfCxb98+paamyu12a/DgwcrLy9M111xT7dzy8nKVl5f775eUlEiSvF6vvF5v0Pyqseoea0now0Xh6oU72oSjnEbjjjIB/7ZU9MGnKfahMfZX7Ct9bPShLst2GWPC+sp86623VFZWpuuuu05Hjx7V3Llz9b//+7/6/PPPddVVVwXN93g8mj17dtB4fn6+4uPjw1kaAABwSFlZmbKzs3XmzBklJibWODfs4eNSZ8+eVY8ePfT4448rJycn6PHqjnykpaXp+PHj1Rbv9XpVUFCgzMxMxcbGOll6k0YfLgpXL9I9G8JYlX3uKKM5Ays1c1uUyitdjV1Oo6EPPk2xD595xlhfJ/tKHxt9KCkpUfv27UMKH4687fLv2rRpo379+mnfvn3VPu52u+V2u4PGY2Nja2xQbY+3FPThoob2ovxC09hBN1R5pavZbEtD0AefptSHxtxXsa/0cbIPdVmu45/zUV5erj179iglJcXpVQEAgAgQ9vDxi1/8Qps2bVJRUZE++ugj/fCHP1RJSYkmT54c7lUBAIAIFPa3Xb766iv9+Mc/1vHjx9WhQwfddNNN2rJli7p27RruVQEAgAgU9vCxcuXKcC8SAAA0I3y3CwAAsIrwAQAArCJ8AAAAqxz/nA8AACSpW+7asCzn4PxxYVkOGg9HPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVVztghYhXGfZAwAajiMfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArOK7XVBnoXxPysH54yxUAgDVq9pPuaONFgyS0j0bVH7BFTCH/VTj4cgHAACwivABAACsInwAAACrCB8AAMAqwgcAALCKq13gCK6IAQBcDkc+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVXO0CAIgooVxNF67lcFWeMzjyAQAArCJ8AAAAqwgfAADAKsIHAACwihNO0aSFckLYvjlZFioBAIQLRz4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFVc7dKC8FHCAICmgCMfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqrnZBownl6hsAQPPDkQ8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBVXu9RTU/ueFK4cAYDG0dT+HkQCjnwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKu42gUBIvGqmXTPBi0Y5Pu3/IKrscsBANSCIx8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwKoWd7WLzc/g5/P+ASCyhesKwMb+2+OONgFXBTb23x6OfAAAAKscCx+LFy9W9+7d1apVKw0YMECbN292alUAACCCOBI+Vq1apenTp2vGjBnasWOHRowYobFjx+rLL790YnUAACCCOBI+nnrqKT3wwAN68MEH1adPHy1atEhpaWlasmSJE6sDAAARJOwnnJ4/f17bt29Xbm5uwHhWVpYKCwuD5peXl6u8vNx//8yZM5KkkydPyuv1Bs33er0qKyvTiRMnFBsbW+f6YirO1jrnxIkTYVlOKEJZV3Uu7UO46olEMZVGZWWVivFG6UJly/14dfrgQx986INPJPWhvn8PLlXd34NL+xCudf270tJSSZIxpvbJJswOHz5sJJkPP/wwYHzevHnmuuuuC5o/a9YsI4kbN27cuHHj1gxuhw4dqjUrOHaprcsVmDCNMUFjkvTEE08oJyfHf7+yslInT57UVVddVe38kpISpaWl6dChQ0pMTAx/4RGCPlxEL3zogw998KEPPvTBx0YfjDEqLS1VampqrXPDHj7at2+v6OhoFRcXB4wfO3ZMnTp1CprvdrvldrsDxq644opa15OYmNiiX0hV6MNF9MKHPvjQBx/64EMffJzuQ7t27UKaF/YTTuPi4jRgwAAVFBQEjBcUFGjo0KHhXh0AAIgwjrztkpOTo0mTJmngwIEaMmSIXnjhBX355Zd65JFHnFgdAACIII6Ej7vuuksnTpzQb3/7Wx05ckTp6elat26dunbt2uBlu91uzZo1K+itmpaGPlxEL3zogw998KEPPvTBp6n1wWVMKNfEAAAAhAff7QIAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArGoS4WPx4sXq3r27WrVqpQEDBmjz5s2XnTtlyhS5XK6g2/XXX++fs3TpUo0YMUJXXnmlrrzySt188836+OOPbWxKg4S7D/9u5cqVcrlcmjBhgkPVh48TfTh9+rSmTp2qlJQUtWrVSn369NG6deuc3pQGcaIPixYtUq9evdS6dWulpaXp5z//uc6dO+f0pjRIXfogSa+88or69++v+Ph4paSk6L777gv6Eq2//e1v6tu3r9xut/r27as1a9Y4uQlhEe4+ROp+UnLmNVGlue4rpdD6YG1fGZZvk2uAlStXmtjYWLN06VKze/du8z//8z+mTZs25osvvqh2/unTp82RI0f8t0OHDpmkpCQza9Ys/5zs7Gzz/PPPmx07dpg9e/aY++67z7Rr18589dVXlraq7pzoQ5WDBw+azp07mxEjRpjbb7/d2Q1pICf6UF5ebgYOHGhuvfVW88EHH5iDBw+azZs3m507d1raqrpzog9/+tOfjNvtNq+88oopKioyGzZsMCkpKWb69OmWtqru6tqHzZs3m6ioKPP000+bAwcOmM2bN5vrr7/eTJgwwT+nsLDQREdHm7y8PLNnzx6Tl5dnYmJizJYtW2xtVp050YdI3E8a40wvqjTnfWUofbC5r2z08DFo0CDzyCOPBIz17t3b5ObmhvT8NWvWGJfLZQ4ePHjZORUVFSYhIcGsWLGiQbU6yak+VFRUmGHDhpkXX3zRTJ48ucn/QjnRhyVLlphrrrnGnD9/Pqy1OsmJPkydOtX853/+Z8C8nJwcM3z48IYX7JC69mHhwoXmmmuuCRh75plnTJcuXfz377zzTnPLLbcEzBkzZoy5++67w1R1+DnRh0tFwn7SGOd60dz3laH0wea+slHfdjl//ry2b9+urKysgPGsrCwVFhaGtIyXXnpJN998c42fnlpWViav16ukpKQG1esUJ/vw29/+Vh06dNADDzwQtnqd4lQfXn/9dQ0ZMkRTp05Vp06dlJ6erry8PF24cCGs9YeLU30YPny4tm/f7j+0fuDAAa1bt07jxo0LX/FhVJ8+DB06VF999ZXWrVsnY4yOHj2qV199NWAb//nPfwYtc8yYMSH31jan+nCppr6flJztRXPfV4bSB5v7Skc+Xj1Ux48f14ULF4K+7bZTp05B34pbnSNHjuitt95Sfn5+jfNyc3PVuXNn3XzzzQ2q1ylO9eHDDz/USy+9pJ07d4azXMc41YcDBw7o3Xff1U9+8hOtW7dO+/bt09SpU1VRUaHf/OY3Yd2GcHCqD3fffbe++eYbDR8+XMYYVVRU6Kc//alyc3PDWn+41KcPQ4cO1SuvvKK77rpL586dU0VFhb7//e/r2Wef9c8pLi6ud28bg1N9uFRT309KzvWiJewrQ+mDzX1lkzjh1OVyBdw3xgSNVWf58uW64oorajwxaMGCBfrzn/+s1atXq1WrVg0t1VHh7ENpaanuueceLV26VO3btw93qY4K9+uhsrJSHTt21AsvvKABAwbo7rvv1owZM7RkyZJwlh124e7De++9p3nz5mnx4sX65JNPtHr1ar355puaM2dOOMsOu7r0Yffu3frZz36m3/zmN9q+fbvWr1+voqKioC+1rG9vG5MTfagSSftJKby9aCn7ylBeEzb3lY165KN9+/aKjo4OSmrHjh0LSnSXMsboj3/8oyZNmqS4uLhq5/zhD39QXl6e3n77bWVkZISt7nBzog//+te/dPDgQY0fP94/VllZKUmKiYnR3r171aNHjzBuRcM59XpISUlRbGysoqOj/WN9+vRRcXGxzp8/f9nXT2Nxqg8zZ87UpEmT9OCDD0qS+vXrp7Nnz+qhhx7SjBkzFBXVJP4v4lefPvzud7/TsGHD9Mtf/lKSlJGRoTZt2mjEiBGaO3euUlJSlJycXK/eNhan+lAlUvaTkjO9OHr0aIvYV4bymrC5r2zUvU1cXJwGDBiggoKCgPGCggINHTq0xudu2rRJ+/fvv+z7cwsXLtScOXO0fv16DRw4MGw1O8GJPvTu3Vu7du3Szp07/bfvf//7Gj16tHbu3Km0tLSwb0dDOfV6GDZsmPbv3+/foUjS//3f/yklJaXJBQ/JuT6UlZUFBYzo6GgZ34nnDS88zOrTh8ttoyT/Ng4ZMiRomRs3bqy1t43FqT5IkbWflJzpRUvZV4bymrC6r3T8lNZaVF0u9NJLL5ndu3eb6dOnmzZt2vjP0s/NzTWTJk0Ket4999xjBg8eXO0yf//735u4uDjz6quvBlx+WFpa6ui2NIQTfbhUJJzB7UQfvvzyS9O2bVszbdo0s3fvXvPmm2+ajh07mrlz5zq6LQ3hRB9mzZplEhISzJ///Gdz4MABs3HjRtOjRw9z5513OrotDVHXPixbtszExMSYxYsXm3/961/mgw8+MAMHDjSDBg3yz/nwww9NdHS0mT9/vtmzZ4+ZP39+xFxqG84+ROJ+0hhnenGp5rivDKUPNveVjR4+jDHm+eefN127djVxcXHmP/7jP8ymTZv8j02ePNmMHDkyYP7p06dN69atzQsvvFDt8rp27WokBd2q+wyMpiTcfbhUJPxCGeNMHwoLC83gwYON2+0211xzjZk3b56pqKhwahPCItx98Hq9xuPxmB49ephWrVqZtLQ08+ijj5pTp045uBUNV9c+PPPMM6Zv376mdevWJiUlxfzkJz8J+uyKv/71r6ZXr14mNjbW9O7d2/ztb3+zsSkNEu4+ROp+0hhnXhP/rrnuK0Ppg619pcuYJni8FQAANFtN6wwzAADQ7BE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYNX/A0NPxQ0UjkopAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(IV_estims).reshape(-1,), bins = 50, density = True)\n",
    "plt.title(f\"Estimated $\\phi_iv$'s\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6701ac-2336-4b05-b047-cd0ff2056642",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- Clearly for the OLS estimator, there is a bias(shifted towards $0.9$) and inconsistency($E(Xz) != 0$) caused by problem mis-specification as seen in the first plot. The reason being we are trying to fit an ARMA process under AR assumptions\n",
    "- Considering the instrumental variable like $x_{t-1}$ as its correlated to $x$ and uncorrelated with the error residuals, performing $IV$ estimation does improve the situation as the the estimated $\\hat{\\beta}$ is close to the true value\n",
    "- The estimator is also consistent with the plot shown above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f08902-7c95-478e-a368-4f9c42fbcea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "### VAR representation of VECM\n",
    "def var_rep(alpha, beta, gamma):\n",
    "    \"\"\"\n",
    "    K: number of variables\n",
    "    L: number of VECM lags\n",
    "    alpha: Kx1 vector of coefficients of cointegrating vector (\\gamma)\n",
    "    beta:  Kx1 cointegrating vector (\\alpha)\n",
    "    gamma: Kx(LK) matrix of coefficients of lagged term [Psi_1,...,Psi_L] where Psi_i is a KxK matrix\n",
    "    \"\"\"\n",
    "    pi = alpha.dot(beta.T)\n",
    "    K = len(beta)\n",
    "    L = int(gamma.shape[1]/gamma.shape[0])+1\n",
    "    A = np.zeros((L, K, K))\n",
    "    A[0] = pi + np.identity(K)\n",
    "    if gamma.size > 0:\n",
    "        A[0] += gamma[:, :K]\n",
    "        A[L - 1] = -gamma[:, K * (L - 2) :]\n",
    "        for i in range(1, L - 1):\n",
    "            A[i] = (\n",
    "                gamma[:, K * i : K * (i + 1)]\n",
    "                - gamma[:, K * (i - 1) : K * i]\n",
    "            )\n",
    "    return A\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "def varsim(coefs, intercept, sig_u, steps=100, initial_values=None, seed=None, nsimulations=None):\n",
    "    \"\"\"\n",
    "    Simulate VAR(p) process, given coefficients and assuming Gaussian noise\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coefs : ndarray\n",
    "        Coefficients for the VAR lags of endog.\n",
    "    intercept : None or ndarray 1-D (neqs,) or (steps, neqs)\n",
    "        This can be either the intercept for each equation or an offset.\n",
    "        If None, then the VAR process has a zero intercept.\n",
    "        If intercept is 1-D, then the same (endog specific) intercept is added\n",
    "        to all observations.\n",
    "        If intercept is 2-D, then it is treated as an offset and is added as\n",
    "        an observation specific intercept to the autoregression. In this case,\n",
    "        the intercept/offset should have same number of rows as steps, and the\n",
    "        same number of columns as endogenous variables (neqs).\n",
    "    sig_u : ndarray\n",
    "        Covariance matrix of the residuals or innovations.\n",
    "        If sig_u is None, then an identity matrix is used.\n",
    "    steps : {None, int}\n",
    "        number of observations to simulate, this includes the initial\n",
    "        observations to start the autoregressive process.\n",
    "        If offset is not None, then exog of the model are used if they were\n",
    "        provided in the model\n",
    "    initial_values : array_like, optional\n",
    "        Initial values for use in the simulation. Shape should be\n",
    "        (nlags, neqs) or (neqs,). Values should be ordered from less to\n",
    "        most recent. Note that this values will be returned by the\n",
    "        simulation as the first values of `endog_simulated` and they\n",
    "        will count for the total number of steps.\n",
    "    seed : {None, int}\n",
    "        If seed is not None, then it will be used with for the random\n",
    "        variables generated by numpy.random.\n",
    "    nsimulations : {None, int}\n",
    "        Number of simulations to perform. If `nsimulations` is None it will\n",
    "        perform one simulation and return value will have shape (steps, neqs).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    endog_simulated : nd_array\n",
    "        Endog of the simulated VAR process. Shape will be (nsimulations, steps, neqs)\n",
    "        or (steps, neqs) if `nsimulations` is None.\n",
    "    \"\"\"\n",
    "    rs = np.random.RandomState(seed=seed)\n",
    "    rmvnorm = rs.multivariate_normal\n",
    "    p, k, k = coefs.shape\n",
    "    nsimulations= int_like(nsimulations, \"nsimulations\", optional=True)\n",
    "    if isinstance(nsimulations, int) and nsimulations <= 0:\n",
    "        raise ValueError(\"nsimulations must be a positive integer if provided\")\n",
    "    if nsimulations is None:\n",
    "        result_shape = (steps, k)\n",
    "        nsimulations = 1\n",
    "    else:\n",
    "        result_shape = (nsimulations, steps, k)\n",
    "    if sig_u is None:\n",
    "        sig_u = np.eye(k)\n",
    "    ugen = rmvnorm(np.zeros(len(sig_u)), sig_u, steps*nsimulations).reshape(nsimulations, steps, k)\n",
    "    result = np.zeros((nsimulations, steps, k))\n",
    "    if intercept is not None:\n",
    "        # intercept can be 2-D like an offset variable\n",
    "        if np.ndim(intercept) > 1:\n",
    "            if not len(intercept) == ugen.shape[1]:\n",
    "                raise ValueError('2-D intercept needs to have length `steps`')\n",
    "        # add intercept/offset also to intial values\n",
    "        result += intercept\n",
    "        result[:,p:] += ugen[:,p:]\n",
    "    else:\n",
    "        result[:,p:] = ugen[:,p:]\n",
    "\n",
    "    initial_values = array_like(initial_values, \"initial_values\", optional=True, maxdim=2)\n",
    "    if initial_values is not None:\n",
    "        if not (initial_values.shape == (p, k) or initial_values.shape == (k,)):\n",
    "            raise ValueError(\"initial_values should have shape (p, k) or (k,) where p is the number of lags and k is the number of equations.\")\n",
    "        result[:,:p] = initial_values\n",
    "\n",
    "    # add in AR terms\n",
    "    for t in range(p, steps):\n",
    "        ygen = result[:,t]\n",
    "        for j in range(p):\n",
    "            ygen += np.dot(coefs[j], result[:,t-j-1].T).T\n",
    "\n",
    "    return result.reshape(result_shape)\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "### VECM with known cointegrating vector\n",
    "def vecm(X, coint_coef, lags, print_output=True, print_short=True):\n",
    "    \n",
    "    #number of variables in the system\n",
    "    K = X.shape[1]\n",
    "\n",
    "    X_diff = X.diff(1)\n",
    "    #add lag terms\n",
    "    for col in list(X_diff):\n",
    "        for i in range(lags):\n",
    "            X_diff[col + \"(-\" + str(i + 1)+\")\"] = X_diff[col].shift(i + 1)  \n",
    "    \n",
    "    if type(coint_coef)==list:\n",
    "        coint_coef = np.array(coint_coef)\n",
    "    \n",
    "    z = X @ coint_coef\n",
    "    if type(z) == pd.Series:\n",
    "        z = z.to_frame()\n",
    "    z.columns = ['e.c.']\n",
    "    \n",
    "    fit_ls = []\n",
    "    for i in range(K):\n",
    "        # X = X_diff.iloc[:,K:]\n",
    "        XX = pd.concat([z.shift(), X_diff.iloc[:,K:]], axis=1)\n",
    "        # print(['e.c.']+X.columns)\n",
    "        # XX.columns = ['e.c.']+list(X.columns)\n",
    "        XX = sm.tools.tools.add_constant(XX)\n",
    "        Y = X_diff.iloc[:, i]\n",
    "        ols_model = sm.regression.linear_model.OLS(Y,XX,missing='drop')\n",
    "        fit_ls.append(ols_model.fit(cov_type='HC0'))\n",
    "\n",
    "    if print_output:\n",
    "        # if print_short:\n",
    "        #     vecm_present(fit_ls)\n",
    "        # else:\n",
    "        for f in fit_ls:\n",
    "            print(f.summary(),'\\n')\n",
    "    return fit_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6116c7d4-ea80-4b1d-b276-681e2d6638de",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de06ac2d-366f-40d0-91b1-0444f5429de4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit for Gamma = (0, 0.3) and Sample size = 250\n",
      "(250, 2)\n",
      "Fitting VECM\n",
      "Fitting VAR on X\n",
      "best lag for VAR is 2\n",
      "Fitting VAR on dX\n",
      "best lag for VAR is 1\n",
      "VECM Gamma vector is given by \n",
      " [[-0.02454521]\n",
      " [ 0.26966199]]\n",
      "\n",
      "VAR Coefficients sum is given by [0.9853656  0.98923007]\n",
      "\n",
      "VAR fit BIC = 0.21388463526907225\n",
      "dVAR fit BIC = 0.3407327213662969\n",
      "\n",
      "Fit for Gamma = (0, 0.3) and Sample size = 2500\n",
      "(2500, 2)\n",
      "Fitting VECM\n",
      "Fitting VAR on X\n",
      "best lag for VAR is 2\n",
      "Fitting VAR on dX\n",
      "best lag for VAR is 8\n",
      "VECM Gamma vector is given by \n",
      " [[0.00911655]\n",
      " [0.27510228]]\n",
      "\n",
      "VAR Coefficients sum is given by [0.9990666  0.99969102]\n",
      "\n",
      "VAR fit BIC = 0.01424306748234102\n",
      "dVAR fit BIC = 0.15754973717669438\n",
      "\n",
      "Fit for Gamma = (0, 0.03) and Sample size = 250\n",
      "(250, 2)\n",
      "Fitting VECM\n",
      "Fitting VAR on X\n",
      "best lag for VAR is 2\n",
      "Fitting VAR on dX\n",
      "best lag for VAR is 1\n",
      "VECM Gamma vector is given by \n",
      " [[0.00584887]\n",
      " [0.02559047]]\n",
      "\n",
      "VAR Coefficients sum is given by [0.97485857 0.98729833]\n",
      "\n",
      "VAR fit BIC = 0.4925498488212521\n",
      "dVAR fit BIC = 0.45804159076616957\n",
      "\n",
      "Fit for Gamma = (0, 0.03) and Sample size = 2500\n",
      "(2500, 2)\n",
      "Fitting VECM\n",
      "Fitting VAR on X\n",
      "best lag for VAR is 2\n",
      "Fitting VAR on dX\n",
      "best lag for VAR is 1\n",
      "VECM Gamma vector is given by \n",
      " [[0.00069759]\n",
      " [0.02959754]]\n",
      "\n",
      "VAR Coefficients sum is given by [0.99938128 1.00033965]\n",
      "\n",
      "VAR fit BIC = -0.02738075806477673\n",
      "dVAR fit BIC = 0.0023631122838680303\n",
      "\n",
      "Fit for Gamma = (-0.25, 0.1) and Sample size = 250\n",
      "(250, 2)\n",
      "Fitting VECM\n",
      "Fitting VAR on X\n",
      "best lag for VAR is 1\n",
      "Fitting VAR on dX\n",
      "best lag for VAR is 1\n",
      "VECM Gamma vector is given by \n",
      " [[-0.27227534]\n",
      " [ 0.09247783]]\n",
      "\n",
      "VAR Coefficients sum is given by [1.00759641 0.97924646]\n",
      "\n",
      "VAR fit BIC = -0.005107113010586639\n",
      "dVAR fit BIC = 0.13320300695980045\n",
      "\n",
      "Fit for Gamma = (-0.25, 0.1) and Sample size = 2500\n",
      "(2500, 2)\n",
      "Fitting VECM\n",
      "Fitting VAR on X\n",
      "best lag for VAR is 2\n",
      "Fitting VAR on dX\n",
      "best lag for VAR is 7\n",
      "VECM Gamma vector is given by \n",
      " [[-0.24004131]\n",
      " [ 0.10078325]]\n",
      "\n",
      "VAR Coefficients sum is given by [0.99485435 0.99706882]\n",
      "\n",
      "VAR fit BIC = 0.05216576074358115\n",
      "dVAR fit BIC = 0.19196064925883988\n",
      "\n",
      "Fit for Gamma = (0, 0) and Sample size = 250\n",
      "(250, 2)\n",
      "Fitting VECM\n",
      "Fitting VAR on X\n",
      "best lag for VAR is 2\n",
      "Fitting VAR on dX\n",
      "best lag for VAR is 1\n",
      "VECM Gamma vector is given by \n",
      " [[-0.01814549]\n",
      " [-0.00222006]]\n",
      "\n",
      "VAR Coefficients sum is given by [0.95194384 0.9766862 ]\n",
      "\n",
      "VAR fit BIC = 0.2993513713640825\n",
      "dVAR fit BIC = 0.23107381676395478\n",
      "\n",
      "Fit for Gamma = (0, 0) and Sample size = 2500\n",
      "(2500, 2)\n",
      "Fitting VECM\n",
      "Fitting VAR on X\n",
      "best lag for VAR is 2\n",
      "Fitting VAR on dX\n",
      "best lag for VAR is 1\n",
      "VECM Gamma vector is given by \n",
      " [[-0.00192136]\n",
      " [-0.0012121 ]]\n",
      "\n",
      "VAR Coefficients sum is given by [0.99761535 0.99593929]\n",
      "\n",
      "VAR fit BIC = -0.03372189047839853\n",
      "dVAR fit BIC = -0.043106564728707886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class VECM_analysis():\n",
    "    def __init__(self,alpha,gamma,psi):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = np.array(gamma).reshape(-1,1)\n",
    "        self.psi = psi\n",
    "        self.var_coeff = var_rep(self.gamma,self.alpha,self.psi)\n",
    "        \n",
    "    def VAR_sim(self,cov_w,T):\n",
    "        var_sim = pd.DataFrame(varsim(self.var_coeff,None,cov_w,steps = T))\n",
    "        var_sim.columns = ['x1', 'x2']\n",
    "        return var_sim\n",
    "\n",
    "    def fit_VECM(self,data,vecm_lags):\n",
    "        vecm = VECM(data, k_ar_diff=vecm_lags)\n",
    "        return vecm.fit()\n",
    "\n",
    "    def fit_best_VAR(self,data):\n",
    "        var = VAR(data)\n",
    "        best_lag = var.select_order().bic\n",
    "        print(f\"best lag for VAR is {best_lag}\")\n",
    "        return var.fit(best_lag)\n",
    "        \n",
    "alpha = np.array([[1],[-1]])\n",
    "psi = np.array([[0.2,-0.1],[0,-0.25]])\n",
    "gammas = [(0,0.3),(0,0.03),(-0.25,0.1),(0,0)]\n",
    "Ts = [250,2500]\n",
    "np.random.seed(48)\n",
    "for gamma in gammas:\n",
    "    for T in Ts:\n",
    "        print(f\"Fit for Gamma = {gamma} and Sample size = {T}\")\n",
    "        sim = VECM_analysis(alpha,gamma,psi)\n",
    "        cov_w = np.eye(2)\n",
    "        sim_data = sim.VAR_sim(cov_w,T)\n",
    "        print(sim_data.shape)\n",
    "        print(\"Fitting VECM\")\n",
    "        fitted_VECM = sim.fit_VECM(sim_data.to_numpy(),1)\n",
    "        print(\"Fitting VAR on X\")\n",
    "        fitted_VAR = sim.fit_best_VAR(sim_data.to_numpy())\n",
    "        print(\"Fitting VAR on dX\")\n",
    "        dsim_data = sim_data.diff().dropna()\n",
    "        fitted_dVAR = sim.fit_best_VAR(dsim_data.to_numpy())\n",
    "        print(f\"VECM Gamma vector is given by \\n {fitted_VECM.alpha}\\n\")\n",
    "        print(f\"VAR Coefficients sum is given by {np.sum(np.sum(fitted_VAR.coefs,axis = 2),axis = 0)}\\n\")\n",
    "        print(f\"VAR fit BIC = {fitted_VAR.bic}\")\n",
    "        print(f\"dVAR fit BIC = {fitted_dVAR.bic}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4416a2b-c7ac-4a6e-8616-9c32d3196781",
   "metadata": {},
   "source": [
    "### Key observations for 5a), 5b)\n",
    "\n",
    "- Clearly, we can see that the VECM estimations for the gamme vector are very close to their true values for both the sample sizes implying robustness in the properties of the estimator( albeit its much more closer in the case of larger values of $T$ )\n",
    "- The VAR coefficients on the $X$ data also sum to $1$ across a row which is in line with the derivation we did in exercise $2$\n",
    "- In majority of the cases, we can see that the best lag ranked by bic is given by $2$ and $1$ when we fit for the first difference implying non stationarity / unit root in the default process. This suggests that we should use first difference specification to counter stationarity\n",
    "- There are few cases where we do see that the first difference series has more lag requirement(especially in the longer series of data) implying that we are doing overdifferencing in this case and in longer sample sizes, we are better off using VAR on default time series for forecasts\n",
    "- Summarizing, VECM approach is the best in short/long term if one wants to understand how the two processes cointegrate as the estimates are consistent for long or short durations\n",
    "- However, in the case of $\\gamma$ being a $0$ vector, we can see that the cointegration approach doesn't offer much insight apart from the fact that the two time series don't cointegrate. In such a case as well, we can use VAR/dVAR to make forecasts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
